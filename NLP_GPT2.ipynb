{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f340b627-ec12-4cdc-bcdf-5dcdfb2b0a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Example tensor on CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('using device:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2463e382-496a-4384-ba7e-25ae0316cddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                               data  \\\n",
      "0           0  iminal Appeal No. 47 of 1963. Appeal by specia...   \n",
      "1           1  Sub section\\n(3) of section 198B provides that...   \n",
      "2           2  Sub section (1) (a) of section 83 states that ...   \n",
      "3           3  Appellant 's counsel on the other hand contend...   \n",
      "4           4  10 sleeping under a Neem tree at some distance...   \n",
      "\n",
      "                                             summary  \n",
      "0  and in convicting the appellant.The appellant ...  \n",
      "1  Furthermore, although the impugned article did...  \n",
      "2  Clause (a) of sub section\\n(1) of section 83 s...  \n",
      "3  Rule 38(1) of the Conduct of Election Rules, 1...  \n",
      "4  It was the obligation of the presiding officer...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filename = \"C://Users//e22cseu0125-legal//Downloads//FD_ind_cs.xlsx\"  \n",
    "df = pd.read_excel(filename)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2958d26a-c7e4-4562-9159-e0397d4eb9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\e22cseu0125-legal\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce2f2ef534d474cbfd34a33d51b89c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e22cseu0125-legal\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\e22cseu0125-legal\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cae519e4bdf4266905da5e5d36a5fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6823f2aa03bb4584bcff7023241cc7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb35d9b8dd3f4fff87cd9a18a18c5e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cb4b563bad4982b09987cecd786672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8322aa99cb244f88c9ebb2ea0d99dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ebe86f33e694e9fac46f804e4ce27de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e22cseu0125-legal\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\e22cseu0125-legal\\AppData\\Local\\Temp\\ipykernel_2588\\915673698.py:61: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117710' max='117710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [117710/117710 2:48:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.345700</td>\n",
       "      <td>2.606619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.541000</td>\n",
       "      <td>2.605600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.493500</td>\n",
       "      <td>2.589323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.539800</td>\n",
       "      <td>2.573117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.165400</td>\n",
       "      <td>2.647623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.229900</td>\n",
       "      <td>2.631049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.320300</td>\n",
       "      <td>2.639132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.409500</td>\n",
       "      <td>2.701658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.293700</td>\n",
       "      <td>2.714661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.181100</td>\n",
       "      <td>2.712375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./gpt2_finetuned\\\\tokenizer_config.json',\n",
       " './gpt2_finetuned\\\\special_tokens_map.json',\n",
       " './gpt2_finetuned\\\\vocab.json',\n",
       " './gpt2_finetuned\\\\merges.txt',\n",
       " './gpt2_finetuned\\\\added_tokens.json',\n",
       " './gpt2_finetuned\\\\tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "model_name = \"gpt2\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "class LegalDataset(Dataset):\n",
    "    def __init__(self, data_frame, tokenizer, max_length=1024):\n",
    "        self.data = data_frame\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        source, target = row['data'], row['summary']\n",
    "        tokenized_input = self.tokenizer(\n",
    "            source, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        tokenized_output = self.tokenizer(\n",
    "            target, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = tokenized_input[\"input_ids\"].squeeze()\n",
    "        attention_mask = tokenized_input[\"attention_mask\"].squeeze()\n",
    "        labels = tokenized_output[\"input_ids\"].squeeze()\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "dataset = LegalDataset(df, tokenizer)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2_finetuned\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir='./logs',\n",
    "    fp16=True,  # Mixed precision training for faster performance\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(\"./gpt2_finetuned\")\n",
    "tokenizer.save_pretrained(\"./gpt2_finetuned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58289811-2e05-4515-8f09-48d0fee8ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root_path():\n",
    "    path = \"./test-data1\"   #CORRECT THIS\n",
    "    return path\n",
    "\n",
    "def get_summary_data(dataset, train):\n",
    "\n",
    "    path = get_root_path()+'/' + train + '-data/judgement'\n",
    "    all_files = glob.glob(path + \"/*.txt\")\n",
    "    data_source = []\n",
    "    names = []\n",
    "    for filename in all_files:\n",
    "        with open(filename, 'r') as f:\n",
    "            p = filename.rfind(\"/\")\n",
    "            names.append(filename[p+1:])\n",
    "            a = f.read()\n",
    "            data_source.append(a)\n",
    "    path = get_root_path() + '/' + train + '-data/summary'\n",
    "    all_files = glob.glob(path + \"/*.txt\")\n",
    "    data_summary = []\n",
    "    for filename in all_files:\n",
    "        with open(filename, 'r') as f:\n",
    "            a = f.read()\n",
    "            l = len(a)\n",
    "            data_summary.append(a)\n",
    "\n",
    "    return names, data_source, data_summary\n",
    "\n",
    "\n",
    "def get_req_len_dict(dataset, istrain):\n",
    "\n",
    "    f = open(get_root_path() +\"/\"+istrain+\"-data\"+\"/stats-\"+ dataset+\"-\" + istrain +\".txt\", \"r\")\n",
    "    a = (f.read())\n",
    "    a = a.split(\"\\n\")\n",
    "    dict_names = {}\n",
    "    for i in a:\n",
    "        b = i.split(\"\t\")\n",
    "        try:\n",
    "            tp = int(b[2])\n",
    "            dict_names[b[0]] = tp\n",
    "        except:\n",
    "            print(b)\n",
    "    return dict_names\n",
    "\n",
    "def split_to_sentences(para):\n",
    "    sents = nltk.sent_tokenize(para)\n",
    "    return sents\n",
    "\n",
    "\n",
    "\n",
    "def nest_sentences(document,chunk_length):\n",
    "\n",
    "    nested = []\n",
    "    sent = []\n",
    "    length = 0\n",
    "    for sentence in nltk.sent_tokenize(document):\n",
    "        length += len(sentence.split(\" \"))\n",
    "        if length < chunk_length:\n",
    "            sent.append(sentence)\n",
    "        else:\n",
    "            nested.append(\" \".join(sent))\n",
    "            sent = []\n",
    "            sent.append(sentence)\n",
    "            length = 0\n",
    "    if len(sent)>0:\n",
    "        nested.append(\" \".join(sent))\n",
    "    return nested\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a104232-0158-4192-be7d-5ea44a834c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "['']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\e22cseu0125-\n",
      "[nltk_data]     legal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\e22cseu0125-\n",
      "[nltk_data]     legal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'4963.txt': 596,\n",
       " '5994.txt': 1048,\n",
       " '7130.txt': 1374,\n",
       " '6118.txt': 569,\n",
       " '4860.txt': 826,\n",
       " '660.txt': 507,\n",
       " '3436.txt': 322,\n",
       " '6276.txt': 599,\n",
       " '2727.txt': 316,\n",
       " '3356.txt': 354,\n",
       " '1531.txt': 514,\n",
       " '2609.txt': 353,\n",
       " '1522.txt': 272,\n",
       " '2392.txt': 480,\n",
       " '1378.txt': 205,\n",
       " '4071.txt': 662,\n",
       " '3168.txt': 736,\n",
       " '232.txt': 1872,\n",
       " '4568.txt': 978,\n",
       " '2440.txt': 1166,\n",
       " '2913.txt': 488,\n",
       " '1697.txt': 1389,\n",
       " '3844.txt': 1448,\n",
       " '5364.txt': 3302,\n",
       " '3542.txt': 266,\n",
       " '266.txt': 410,\n",
       " '3210.txt': 603,\n",
       " '1974.txt': 529,\n",
       " '6003.txt': 1571,\n",
       " '5141.txt': 919,\n",
       " '2207.txt': 717,\n",
       " '2593.txt': 630,\n",
       " '1195.txt': 531,\n",
       " '1406.txt': 410,\n",
       " '2627.txt': 752,\n",
       " '6270.txt': 421,\n",
       " '3924.txt': 769,\n",
       " '6778.txt': 10008,\n",
       " '2124.txt': 163,\n",
       " '78.txt': 398,\n",
       " '4316.txt': 1720,\n",
       " '1778.txt': 468,\n",
       " '314.txt': 258,\n",
       " '690.txt': 1066,\n",
       " '1789.txt': 346,\n",
       " '2122.txt': 3873,\n",
       " '2796.txt': 479,\n",
       " '6852.txt': 669,\n",
       " '2649.txt': 466,\n",
       " '6728.txt': 436,\n",
       " '2052.txt': 746,\n",
       " '5266.txt': 6079,\n",
       " '5248.txt': 1089,\n",
       " '2304.txt': 855,\n",
       " '6881.txt': 854,\n",
       " '6668.txt': 471,\n",
       " '3531.txt': 624,\n",
       " '415.txt': 305,\n",
       " '3019.txt': 274,\n",
       " '2248.txt': 569,\n",
       " '715.txt': 249,\n",
       " '5142.txt': 600,\n",
       " '4938.txt': 901,\n",
       " '2065.txt': 616,\n",
       " '4641.txt': 1457,\n",
       " '380.txt': 303,\n",
       " '7109.txt': 623,\n",
       " '5707.txt': 1160,\n",
       " '5538.txt': 776,\n",
       " '1762.txt': 552,\n",
       " '652.txt': 246,\n",
       " '496.txt': 429,\n",
       " '5397.txt': 752,\n",
       " '4782.txt': 726,\n",
       " '2657.txt': 432,\n",
       " '5937.txt': 241,\n",
       " '4807.txt': 548,\n",
       " '4451.txt': 578,\n",
       " '1181.txt': 321,\n",
       " '6245.txt': 212,\n",
       " '3292.txt': 577,\n",
       " '4917.txt': 3299,\n",
       " '6622.txt': 1169,\n",
       " '1329.txt': 343,\n",
       " '3893.txt': 953,\n",
       " '5888.txt': 226,\n",
       " '6521.txt': 1646,\n",
       " '3602.txt': 421,\n",
       " '6647.txt': 1274,\n",
       " '6157.txt': 1906,\n",
       " '6413.txt': 586,\n",
       " '5471.txt': 1078,\n",
       " '3442.txt': 666,\n",
       " '362.txt': 1038,\n",
       " '2035.txt': 553,\n",
       " '5597.txt': 323,\n",
       " '2256.txt': 674,\n",
       " '5861.txt': 1062,\n",
       " '4480.txt': 2288,\n",
       " '784.txt': 463}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from nltk import tokenize\n",
    "import nltk\n",
    "import transformers\n",
    "import torch\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "dataset = \"IN\"\n",
    "names, data_source, data_summary = get_summary_data(dataset, \"test\")\n",
    "print(len(names))\n",
    "print(len(data_source))\n",
    "print(len(data_summary))\n",
    "dict_names = get_req_len_dict(dataset, \"test\")\n",
    "dict_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2176d5e-f1bd-4363-b0a7-9dfb41f2ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_gpu(nested_sentences,p=0.2):\n",
    "\n",
    "  device = 'cuda'\n",
    "  summaries = []\n",
    "  for nested in nested_sentences:\n",
    "    l = int(p * len(nested.split(\" \")))\n",
    "    input_tokenized = tokenizer.encode(nested, truncation=True, return_tensors='pt')\n",
    "    input_tokenized = input_tokenized.to(device)\n",
    "    summary_ids = model.to(device).generate(input_tokenized,\n",
    "                                      length_penalty=0.01,\n",
    "                                      min_length=l-5,\n",
    "                                      max_length=2048)\n",
    "    output = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "    summaries.append(output)\n",
    "  summaries = [sentence for sublist in summaries for sentence in sublist]\n",
    "  return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "796099b9-0392-4fbc-8464-664b8357c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./output_gpt2/\"\n",
    "import os\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5abcf08-19ba-49fa-a13a-506b5619c34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e22cseu0125-legal\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:657: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `0.01` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Name: 1181.txt\n",
      "0: judgement\\1181.txt - 3387 : 321 ,0.09477413640389726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (1024). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n",
      "Constructed Path: ./output_gpt2/judgement\\1181.txt\n",
      "Directory does not exist: output_gpt2\\judgement\n",
      "Directory created: output_gpt2\\judgement\n",
      "The file does not exist: output_gpt2\\judgement\\1181.txt\n",
      "Base Name: 1195.txt\n",
      "1: judgement\\1195.txt - 4234 : 531 ,0.12541332073689182\n",
      "531\n",
      "Constructed Path: ./output_gpt2/judgement\\1195.txt\n",
      "The file does not exist: output_gpt2\\judgement\\1195.txt\n",
      "Base Name: 1329.txt\n",
      "2: judgement\\1329.txt - 2990 : 343 ,0.11471571906354515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343\n",
      "Constructed Path: ./output_gpt2/judgement\\1329.txt\n",
      "The file does not exist: output_gpt2\\judgement\\1329.txt\n",
      "Base Name: 1378.txt\n",
      "3: judgement\\1378.txt - 2202 : 205 ,0.09309718437783833\n",
      "205\n",
      "Constructed Path: ./output_gpt2/judgement\\1378.txt\n",
      "The file does not exist: output_gpt2\\judgement\\1378.txt\n",
      "Base Name: 1406.txt\n",
      "4: judgement\\1406.txt - 2089 : 410 ,0.19626615605552897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n",
      "Constructed Path: ./output_gpt2/judgement\\1406.txt\n",
      "The file does not exist: output_gpt2\\judgement\\1406.txt\n",
      "Base Name: 1522.txt\n",
      "5: judgement\\1522.txt - 3109 : 272 ,0.0874879382438083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272\n",
      "Constructed Path: ./output_gpt2/judgement\\1522.txt\n",
      "The file does not exist: output_gpt2\\judgement\\1522.txt\n",
      "Base Name: 1531.txt\n",
      "6: judgement\\1531.txt - 3038 : 514 ,0.16919025674786042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514\n",
      "Constructed Path: ./output_gpt2/judgement\\1531.txt\n",
      "The file does not exist: output_gpt2\\judgement\\1531.txt\n",
      "Base Name: 1697.txt\n",
      "7: judgement\\1697.txt - 12399 : 1389 ,0.11202516331962255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1389\n",
      "Constructed Path: ./output_gpt2/judgement\\1697.txt\n",
      "The file does not exist: output_gpt2\\judgement\\1697.txt\n",
      "Base Name: 1762.txt\n",
      "8: judgement\\1762.txt - 4819 : 552 ,0.11454658642871965\n",
      "552\n",
      "Constructed Path: ./output_gpt2/judgement\\1762.txt\n",
      "The file does not exist: output_gpt2\\judgement\\1762.txt\n",
      "Base Name: 1778.txt\n",
      "9: judgement\\1778.txt - 1463 : 468 ,0.3198906356801094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "Constructed Path: ./output_gpt2/judgement\\1778.txt\n",
      "The file does not exist: output_gpt2\\judgement\\1778.txt\n",
      "Base Name: 1789.txt\n",
      "10: judgement\\1789.txt - 2076 : 346 ,0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346\n",
      "Constructed Path: ./output_gpt2/judgement\\1789.txt\n",
      "The file does not exist: output_gpt2\\judgement\\1789.txt\n",
      "Base Name: 1974.txt\n",
      "11: judgement\\1974.txt - 2686 : 529 ,0.19694713328369323\n",
      "529\n",
      "Constructed Path: ./output_gpt2/judgement\\1974.txt\n",
      "The file does not exist: output_gpt2\\judgement\\1974.txt\n",
      "Base Name: 2035.txt\n",
      "12: judgement\\2035.txt - 4644 : 553 ,0.11907838070628768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553\n",
      "Constructed Path: ./output_gpt2/judgement\\2035.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2035.txt\n",
      "Base Name: 2052.txt\n",
      "13: judgement\\2052.txt - 3408 : 746 ,0.21889671361502347\n",
      "746\n",
      "Constructed Path: ./output_gpt2/judgement\\2052.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2052.txt\n",
      "Base Name: 2065.txt\n",
      "14: judgement\\2065.txt - 5353 : 616 ,0.11507565850924716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616\n",
      "Constructed Path: ./output_gpt2/judgement\\2065.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2065.txt\n",
      "Base Name: 2122.txt\n",
      "15: judgement\\2122.txt - 13358 : 3873 ,0.2899386135649049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3873\n",
      "Constructed Path: ./output_gpt2/judgement\\2122.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2122.txt\n",
      "Base Name: 2124.txt\n",
      "16: judgement\\2124.txt - 2526 : 163 ,0.06452889944576405\n",
      "163\n",
      "Constructed Path: ./output_gpt2/judgement\\2124.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2124.txt\n",
      "Base Name: 2207.txt\n",
      "17: judgement\\2207.txt - 2235 : 717 ,0.3208053691275168\n",
      "717\n",
      "Constructed Path: ./output_gpt2/judgement\\2207.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2207.txt\n",
      "Base Name: 2248.txt\n",
      "18: judgement\\2248.txt - 3778 : 569 ,0.1506087877183695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n",
      "Constructed Path: ./output_gpt2/judgement\\2248.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2248.txt\n",
      "Base Name: 2256.txt\n",
      "19: judgement\\2256.txt - 6521 : 674 ,0.10335838061646986\n",
      "674\n",
      "Constructed Path: ./output_gpt2/judgement\\2256.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2256.txt\n",
      "Base Name: 2304.txt\n",
      "20: judgement\\2304.txt - 4199 : 855 ,0.20361990950226244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "855\n",
      "Constructed Path: ./output_gpt2/judgement\\2304.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2304.txt\n",
      "Base Name: 232.txt\n",
      "21: judgement\\232.txt - 28324 : 1872 ,0.06609235983618134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872\n",
      "Constructed Path: ./output_gpt2/judgement\\232.txt\n",
      "The file does not exist: output_gpt2\\judgement\\232.txt\n",
      "Base Name: 2392.txt\n",
      "22: judgement\\2392.txt - 2464 : 480 ,0.19480519480519481\n",
      "480\n",
      "Constructed Path: ./output_gpt2/judgement\\2392.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2392.txt\n",
      "Base Name: 2440.txt\n",
      "23: judgement\\2440.txt - 5064 : 1166 ,0.23025276461295419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166\n",
      "Constructed Path: ./output_gpt2/judgement\\2440.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2440.txt\n",
      "Base Name: 2593.txt\n",
      "24: judgement\\2593.txt - 2755 : 630 ,0.22867513611615245\n",
      "630\n",
      "Constructed Path: ./output_gpt2/judgement\\2593.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2593.txt\n",
      "Base Name: 2609.txt\n",
      "25: judgement\\2609.txt - 2298 : 353 ,0.1536118363794604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353\n",
      "Constructed Path: ./output_gpt2/judgement\\2609.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2609.txt\n",
      "Base Name: 2627.txt\n",
      "26: judgement\\2627.txt - 2820 : 752 ,0.26666666666666666\n",
      "752\n",
      "Constructed Path: ./output_gpt2/judgement\\2627.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2627.txt\n",
      "Base Name: 2649.txt\n",
      "27: judgement\\2649.txt - 3043 : 466 ,0.15313835031219192\n",
      "466\n",
      "Constructed Path: ./output_gpt2/judgement\\2649.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2649.txt\n",
      "Base Name: 2657.txt\n",
      "28: judgement\\2657.txt - 2382 : 432 ,0.181360201511335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432\n",
      "Constructed Path: ./output_gpt2/judgement\\2657.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2657.txt\n",
      "Base Name: 266.txt\n",
      "29: judgement\\266.txt - 6398 : 410 ,0.06408252578930916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n",
      "Constructed Path: ./output_gpt2/judgement\\266.txt\n",
      "The file does not exist: output_gpt2\\judgement\\266.txt\n",
      "Base Name: 2727.txt\n",
      "30: judgement\\2727.txt - 1472 : 316 ,0.21467391304347827\n",
      "316\n",
      "Constructed Path: ./output_gpt2/judgement\\2727.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2727.txt\n",
      "Base Name: 2796.txt\n",
      "31: judgement\\2796.txt - 1274 : 479 ,0.37598116169544743\n",
      "479\n",
      "Constructed Path: ./output_gpt2/judgement\\2796.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2796.txt\n",
      "Base Name: 2913.txt\n",
      "32: judgement\\2913.txt - 1949 : 488 ,0.2503848127244741\n",
      "488\n",
      "Constructed Path: ./output_gpt2/judgement\\2913.txt\n",
      "The file does not exist: output_gpt2\\judgement\\2913.txt\n",
      "Base Name: 3019.txt\n",
      "33: judgement\\3019.txt - 1498 : 274 ,0.1829105473965287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274\n",
      "Constructed Path: ./output_gpt2/judgement\\3019.txt\n",
      "The file does not exist: output_gpt2\\judgement\\3019.txt\n",
      "Base Name: 314.txt\n",
      "34: judgement\\314.txt - 2829 : 258 ,0.0911983032873807\n",
      "258\n",
      "Constructed Path: ./output_gpt2/judgement\\314.txt\n",
      "The file does not exist: output_gpt2\\judgement\\314.txt\n",
      "Base Name: 3168.txt\n",
      "35: judgement\\3168.txt - 3174 : 736 ,0.2318840579710145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736\n",
      "Constructed Path: ./output_gpt2/judgement\\3168.txt\n",
      "The file does not exist: output_gpt2\\judgement\\3168.txt\n",
      "Base Name: 3210.txt\n",
      "36: judgement\\3210.txt - 3650 : 603 ,0.1652054794520548\n",
      "603\n",
      "Constructed Path: ./output_gpt2/judgement\\3210.txt\n",
      "The file does not exist: output_gpt2\\judgement\\3210.txt\n",
      "Base Name: 3292.txt\n",
      "37: judgement\\3292.txt - 1611 : 577 ,0.3581626319056487\n",
      "577\n",
      "Constructed Path: ./output_gpt2/judgement\\3292.txt\n",
      "The file does not exist: output_gpt2\\judgement\\3292.txt\n",
      "Base Name: 3356.txt\n",
      "38: judgement\\3356.txt - 1874 : 354 ,0.18890074706510138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354\n",
      "Constructed Path: ./output_gpt2/judgement\\3356.txt\n",
      "The file does not exist: output_gpt2\\judgement\\3356.txt\n",
      "Base Name: 3436.txt\n",
      "39: judgement\\3436.txt - 1692 : 322 ,0.19030732860520094\n",
      "322\n",
      "Constructed Path: ./output_gpt2/judgement\\3436.txt\n",
      "The file does not exist: output_gpt2\\judgement\\3436.txt\n",
      "Base Name: 3442.txt\n",
      "40: judgement\\3442.txt - 5175 : 666 ,0.12869565217391304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666\n",
      "Constructed Path: ./output_gpt2/judgement\\3442.txt\n",
      "The file does not exist: output_gpt2\\judgement\\3442.txt\n",
      "Base Name: 3531.txt\n",
      "41: judgement\\3531.txt - 2845 : 624 ,0.21933216168717048\n",
      "624\n",
      "Constructed Path: ./output_gpt2/judgement\\3531.txt\n",
      "The file does not exist: output_gpt2\\judgement\\3531.txt\n",
      "Base Name: 3542.txt\n",
      "42: judgement\\3542.txt - 2250 : 266 ,0.11822222222222223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266\n",
      "Constructed Path: ./output_gpt2/judgement\\3542.txt\n",
      "The file does not exist: output_gpt2\\judgement\\3542.txt\n",
      "Base Name: 3602.txt\n",
      "43: judgement\\3602.txt - 1978 : 421 ,0.2128412537917088\n",
      "421\n",
      "Constructed Path: ./output_gpt2/judgement\\3602.txt\n",
      "The file does not exist: output_gpt2\\judgement\\3602.txt\n",
      "Base Name: 362.txt\n",
      "44: judgement\\362.txt - 6285 : 1038 ,0.16515513126491646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1038\n",
      "Constructed Path: ./output_gpt2/judgement\\362.txt\n",
      "The file does not exist: output_gpt2\\judgement\\362.txt\n",
      "Base Name: 380.txt\n",
      "45: judgement\\380.txt - 1833 : 303 ,0.16530278232405893\n",
      "303\n",
      "Constructed Path: ./output_gpt2/judgement\\380.txt\n",
      "The file does not exist: output_gpt2\\judgement\\380.txt\n",
      "Base Name: 3844.txt\n",
      "46: judgement\\3844.txt - 3272 : 1448 ,0.44254278728606355\n",
      "1448\n",
      "Constructed Path: ./output_gpt2/judgement\\3844.txt\n",
      "The file does not exist: output_gpt2\\judgement\\3844.txt\n",
      "Base Name: 3893.txt\n",
      "47: judgement\\3893.txt - 2015 : 953 ,0.47295285359801487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "953\n",
      "Constructed Path: ./output_gpt2/judgement\\3893.txt\n",
      "The file does not exist: output_gpt2\\judgement\\3893.txt\n",
      "Base Name: 3924.txt\n",
      "48: judgement\\3924.txt - 2725 : 769 ,0.2822018348623853\n",
      "769\n",
      "Constructed Path: ./output_gpt2/judgement\\3924.txt\n",
      "The file does not exist: output_gpt2\\judgement\\3924.txt\n",
      "Base Name: 4071.txt\n",
      "49: judgement\\4071.txt - 2433 : 662 ,0.27209206740649405\n",
      "662\n",
      "Constructed Path: ./output_gpt2/judgement\\4071.txt\n",
      "The file does not exist: output_gpt2\\judgement\\4071.txt\n",
      "Base Name: 415.txt\n",
      "50: judgement\\415.txt - 3322 : 305 ,0.09181216134858519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305\n",
      "Constructed Path: ./output_gpt2/judgement\\415.txt\n",
      "The file does not exist: output_gpt2\\judgement\\415.txt\n",
      "Base Name: 4316.txt\n",
      "51: judgement\\4316.txt - 6756 : 1720 ,0.2545885139135583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1720\n",
      "Constructed Path: ./output_gpt2/judgement\\4316.txt\n",
      "The file does not exist: output_gpt2\\judgement\\4316.txt\n",
      "Base Name: 4451.txt\n",
      "52: judgement\\4451.txt - 1517 : 578 ,0.3810151615029664\n",
      "578\n",
      "Constructed Path: ./output_gpt2/judgement\\4451.txt\n",
      "The file does not exist: output_gpt2\\judgement\\4451.txt\n",
      "Base Name: 4480.txt\n",
      "53: judgement\\4480.txt - 7093 : 2288 ,0.3225715494149161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2288\n",
      "Constructed Path: ./output_gpt2/judgement\\4480.txt\n",
      "The file does not exist: output_gpt2\\judgement\\4480.txt\n",
      "Base Name: 4568.txt\n",
      "54: judgement\\4568.txt - 9067 : 978 ,0.10786368148229844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978\n",
      "Constructed Path: ./output_gpt2/judgement\\4568.txt\n",
      "The file does not exist: output_gpt2\\judgement\\4568.txt\n",
      "Base Name: 4641.txt\n",
      "55: judgement\\4641.txt - 6934 : 1457 ,0.21012402653591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1457\n",
      "Constructed Path: ./output_gpt2/judgement\\4641.txt\n",
      "The file does not exist: output_gpt2\\judgement\\4641.txt\n",
      "Base Name: 4782.txt\n",
      "56: judgement\\4782.txt - 3411 : 726 ,0.21284080914687775\n",
      "726\n",
      "Constructed Path: ./output_gpt2/judgement\\4782.txt\n",
      "The file does not exist: output_gpt2\\judgement\\4782.txt\n",
      "Base Name: 4807.txt\n",
      "57: judgement\\4807.txt - 963 : 548 ,0.569055036344756\n",
      "548\n",
      "Constructed Path: ./output_gpt2/judgement\\4807.txt\n",
      "The file does not exist: output_gpt2\\judgement\\4807.txt\n",
      "Base Name: 4860.txt\n",
      "58: judgement\\4860.txt - 2389 : 826 ,0.3457513604018418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826\n",
      "Constructed Path: ./output_gpt2/judgement\\4860.txt\n",
      "The file does not exist: output_gpt2\\judgement\\4860.txt\n",
      "Base Name: 4917.txt\n",
      "59: judgement\\4917.txt - 10531 : 3299 ,0.3132655968094198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3299\n",
      "Constructed Path: ./output_gpt2/judgement\\4917.txt\n",
      "The file does not exist: output_gpt2\\judgement\\4917.txt\n",
      "Base Name: 4938.txt\n",
      "60: judgement\\4938.txt - 1666 : 901 ,0.5408163265306123\n",
      "901\n",
      "Constructed Path: ./output_gpt2/judgement\\4938.txt\n",
      "The file does not exist: output_gpt2\\judgement\\4938.txt\n",
      "Base Name: 496.txt\n",
      "61: judgement\\496.txt - 4725 : 429 ,0.09079365079365079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "Constructed Path: ./output_gpt2/judgement\\496.txt\n",
      "The file does not exist: output_gpt2\\judgement\\496.txt\n",
      "Base Name: 4963.txt\n",
      "62: judgement\\4963.txt - 1286 : 596 ,0.463452566096423\n",
      "596\n",
      "Constructed Path: ./output_gpt2/judgement\\4963.txt\n",
      "The file does not exist: output_gpt2\\judgement\\4963.txt\n",
      "Base Name: 5141.txt\n",
      "63: judgement\\5141.txt - 3505 : 919 ,0.2621968616262482\n",
      "919\n",
      "Constructed Path: ./output_gpt2/judgement\\5141.txt\n",
      "The file does not exist: output_gpt2\\judgement\\5141.txt\n",
      "Base Name: 5142.txt\n",
      "64: judgement\\5142.txt - 2229 : 600 ,0.2691790040376851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "Constructed Path: ./output_gpt2/judgement\\5142.txt\n",
      "The file does not exist: output_gpt2\\judgement\\5142.txt\n",
      "Base Name: 5248.txt\n",
      "65: judgement\\5248.txt - 3849 : 1089 ,0.2829306313328137\n",
      "1089\n",
      "Constructed Path: ./output_gpt2/judgement\\5248.txt\n",
      "The file does not exist: output_gpt2\\judgement\\5248.txt\n",
      "Base Name: 5266.txt\n",
      "66: judgement\\5266.txt - 18433 : 6079 ,0.32978896544241304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6079\n",
      "Constructed Path: ./output_gpt2/judgement\\5266.txt\n",
      "The file does not exist: output_gpt2\\judgement\\5266.txt\n",
      "Base Name: 5364.txt\n",
      "67: judgement\\5364.txt - 15012 : 3302 ,0.21995736743938182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3302\n",
      "Constructed Path: ./output_gpt2/judgement\\5364.txt\n",
      "The file does not exist: output_gpt2\\judgement\\5364.txt\n",
      "Base Name: 5397.txt\n",
      "68: judgement\\5397.txt - 2159 : 752 ,0.34830940250115794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752\n",
      "Constructed Path: ./output_gpt2/judgement\\5397.txt\n",
      "The file does not exist: output_gpt2\\judgement\\5397.txt\n",
      "Base Name: 5471.txt\n",
      "69: judgement\\5471.txt - 3771 : 1078 ,0.28586581808538847\n",
      "1078\n",
      "Constructed Path: ./output_gpt2/judgement\\5471.txt\n",
      "The file does not exist: output_gpt2\\judgement\\5471.txt\n",
      "Base Name: 5538.txt\n",
      "70: judgement\\5538.txt - 4333 : 776 ,0.17909069928456034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776\n",
      "Constructed Path: ./output_gpt2/judgement\\5538.txt\n",
      "The file does not exist: output_gpt2\\judgement\\5538.txt\n",
      "Base Name: 5597.txt\n",
      "71: judgement\\5597.txt - 3583 : 323 ,0.09014792073681273\n",
      "323\n",
      "Constructed Path: ./output_gpt2/judgement\\5597.txt\n",
      "The file does not exist: output_gpt2\\judgement\\5597.txt\n",
      "Base Name: 5707.txt\n",
      "72: judgement\\5707.txt - 3877 : 1160 ,0.2992004126902244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1160\n",
      "Constructed Path: ./output_gpt2/judgement\\5707.txt\n",
      "The file does not exist: output_gpt2\\judgement\\5707.txt\n",
      "Base Name: 5861.txt\n",
      "73: judgement\\5861.txt - 5299 : 1062 ,0.20041517267408945\n",
      "1062\n",
      "Constructed Path: ./output_gpt2/judgement\\5861.txt\n",
      "The file does not exist: output_gpt2\\judgement\\5861.txt\n",
      "Base Name: 5888.txt\n",
      "74: judgement\\5888.txt - 548 : 226 ,0.4124087591240876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n",
      "Constructed Path: ./output_gpt2/judgement\\5888.txt\n",
      "The file does not exist: output_gpt2\\judgement\\5888.txt\n",
      "Base Name: 5937.txt\n",
      "75: judgement\\5937.txt - 499 : 241 ,0.48296593186372744\n",
      "241\n",
      "Constructed Path: ./output_gpt2/judgement\\5937.txt\n",
      "The file does not exist: output_gpt2\\judgement\\5937.txt\n",
      "Base Name: 5994.txt\n",
      "76: judgement\\5994.txt - 5963 : 1048 ,0.17575046117725976\n",
      "1048\n",
      "Constructed Path: ./output_gpt2/judgement\\5994.txt\n",
      "The file does not exist: output_gpt2\\judgement\\5994.txt\n",
      "Base Name: 6003.txt\n",
      "77: judgement\\6003.txt - 6388 : 1571 ,0.24592986850344395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1571\n",
      "Constructed Path: ./output_gpt2/judgement\\6003.txt\n",
      "The file does not exist: output_gpt2\\judgement\\6003.txt\n",
      "Base Name: 6118.txt\n",
      "78: judgement\\6118.txt - 2109 : 569 ,0.26979611190137504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n",
      "Constructed Path: ./output_gpt2/judgement\\6118.txt\n",
      "The file does not exist: output_gpt2\\judgement\\6118.txt\n",
      "Base Name: 6157.txt\n",
      "79: judgement\\6157.txt - 8215 : 1906 ,0.23201460742544128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1906\n",
      "Constructed Path: ./output_gpt2/judgement\\6157.txt\n",
      "The file does not exist: output_gpt2\\judgement\\6157.txt\n",
      "Base Name: 6245.txt\n",
      "80: judgement\\6245.txt - 624 : 212 ,0.33974358974358976\n",
      "212\n",
      "Constructed Path: ./output_gpt2/judgement\\6245.txt\n",
      "The file does not exist: output_gpt2\\judgement\\6245.txt\n",
      "Base Name: 6270.txt\n",
      "81: judgement\\6270.txt - 2029 : 421 ,0.2074913750616067\n",
      "421\n",
      "Constructed Path: ./output_gpt2/judgement\\6270.txt\n",
      "The file does not exist: output_gpt2\\judgement\\6270.txt\n",
      "Base Name: 6276.txt\n",
      "82: judgement\\6276.txt - 3590 : 599 ,0.16685236768802228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599\n",
      "Constructed Path: ./output_gpt2/judgement\\6276.txt\n",
      "The file does not exist: output_gpt2\\judgement\\6276.txt\n",
      "Base Name: 6413.txt\n",
      "83: judgement\\6413.txt - 1368 : 586 ,0.4283625730994152\n",
      "586\n",
      "Constructed Path: ./output_gpt2/judgement\\6413.txt\n",
      "The file does not exist: output_gpt2\\judgement\\6413.txt\n",
      "Base Name: 652.txt\n",
      "84: judgement\\652.txt - 6087 : 246 ,0.040413997042878264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n",
      "Constructed Path: ./output_gpt2/judgement\\652.txt\n",
      "The file does not exist: output_gpt2\\judgement\\652.txt\n",
      "Base Name: 6521.txt\n",
      "85: judgement\\6521.txt - 10081 : 1646 ,0.1632774526336673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646\n",
      "Constructed Path: ./output_gpt2/judgement\\6521.txt\n",
      "The file does not exist: output_gpt2\\judgement\\6521.txt\n",
      "Base Name: 660.txt\n",
      "86: judgement\\660.txt - 13689 : 507 ,0.037037037037037035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507\n",
      "Constructed Path: ./output_gpt2/judgement\\660.txt\n",
      "The file does not exist: output_gpt2\\judgement\\660.txt\n",
      "Base Name: 6622.txt\n",
      "87: judgement\\6622.txt - 7991 : 1169 ,0.14628957577274435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169\n",
      "Constructed Path: ./output_gpt2/judgement\\6622.txt\n",
      "The file does not exist: output_gpt2\\judgement\\6622.txt\n",
      "Base Name: 6647.txt\n",
      "88: judgement\\6647.txt - 5883 : 1274 ,0.21655617882032976\n",
      "1274\n",
      "Constructed Path: ./output_gpt2/judgement\\6647.txt\n",
      "The file does not exist: output_gpt2\\judgement\\6647.txt\n",
      "Base Name: 6668.txt\n",
      "89: judgement\\6668.txt - 1392 : 471 ,0.33836206896551724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471\n",
      "Constructed Path: ./output_gpt2/judgement\\6668.txt\n",
      "The file does not exist: output_gpt2\\judgement\\6668.txt\n",
      "Base Name: 6728.txt\n",
      "90: judgement\\6728.txt - 830 : 436 ,0.5253012048192771\n",
      "436\n",
      "Constructed Path: ./output_gpt2/judgement\\6728.txt\n",
      "The file does not exist: output_gpt2\\judgement\\6728.txt\n",
      "Base Name: 6778.txt\n",
      "91: judgement\\6778.txt - 38530 : 10008 ,0.2597456527381261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10008\n",
      "Constructed Path: ./output_gpt2/judgement\\6778.txt\n",
      "The file does not exist: output_gpt2\\judgement\\6778.txt\n",
      "Base Name: 6852.txt\n",
      "92: judgement\\6852.txt - 1717 : 669 ,0.38963308095515437\n",
      "669\n",
      "Constructed Path: ./output_gpt2/judgement\\6852.txt\n",
      "The file does not exist: output_gpt2\\judgement\\6852.txt\n",
      "Base Name: 6881.txt\n",
      "93: judgement\\6881.txt - 2999 : 854 ,0.2847615871957319\n",
      "854\n",
      "Constructed Path: ./output_gpt2/judgement\\6881.txt\n",
      "The file does not exist: output_gpt2\\judgement\\6881.txt\n",
      "Base Name: 690.txt\n",
      "94: judgement\\690.txt - 4022 : 1066 ,0.2650422675285927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066\n",
      "Constructed Path: ./output_gpt2/judgement\\690.txt\n",
      "The file does not exist: output_gpt2\\judgement\\690.txt\n",
      "Base Name: 7109.txt\n",
      "95: judgement\\7109.txt - 2032 : 623 ,0.3065944881889764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623\n",
      "Constructed Path: ./output_gpt2/judgement\\7109.txt\n",
      "The file does not exist: output_gpt2\\judgement\\7109.txt\n",
      "Base Name: 7130.txt\n",
      "96: judgement\\7130.txt - 6171 : 1374 ,0.22265435099659697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1374\n",
      "Constructed Path: ./output_gpt2/judgement\\7130.txt\n",
      "The file does not exist: output_gpt2\\judgement\\7130.txt\n",
      "Base Name: 715.txt\n",
      "97: judgement\\715.txt - 1346 : 249 ,0.1849925705794948\n",
      "249\n",
      "Constructed Path: ./output_gpt2/judgement\\715.txt\n",
      "The file does not exist: output_gpt2\\judgement\\715.txt\n",
      "Base Name: 78.txt\n",
      "98: judgement\\78.txt - 2035 : 398 ,0.1955773955773956\n",
      "398\n",
      "Constructed Path: ./output_gpt2/judgement\\78.txt\n",
      "The file does not exist: output_gpt2\\judgement\\78.txt\n",
      "Base Name: 784.txt\n",
      "99: judgement\\784.txt - 3712 : 463 ,0.12473060344827586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n",
      "Constructed Path: ./output_gpt2/judgement\\784.txt\n",
      "The file does not exist: output_gpt2\\judgement\\784.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for i in range(len(data_source)):\n",
    "    name = names[i]\n",
    "    doc = data_source[i]\n",
    "    wc = doc.split(\" \")\n",
    "    input_len = len(wc)\n",
    "        # Extract only the file name (e.g., '1181.txt') from `name`\n",
    "    base_name = os.path.basename(name)\n",
    "    \n",
    "    # Debug to verify\n",
    "    print(f\"Base Name: {base_name}\")\n",
    "    \n",
    "    # Access the correct key in `dict_names`\n",
    "    if base_name not in dict_names:\n",
    "        print(f\"KeyError: '{base_name}' not found in dict_names\")\n",
    "        continue  # Skip this iteration if the key is missing\n",
    "    \n",
    "    req_len = dict_names[base_name]\n",
    "\n",
    "    print(str(i) + \": \" + name + \" - \" + str(input_len) + \" : \" + str(req_len), end=\" ,\")\n",
    "\n",
    "    nested = nest_sentences(doc, 1024)\n",
    "    l = int(req_len / len(nested))\n",
    "    p = float(req_len / input_len)\n",
    "    print(p)\n",
    "\n",
    "    abs_summ = generate_summary_gpu(nested, p)\n",
    "\n",
    "    abs_summ = \" \".join(abs_summ)\n",
    "    if len(abs_summ.split(\" \")) > req_len:\n",
    "        abs_summ = abs_summ.split(\" \")\n",
    "        abs_summ = abs_summ[:req_len]\n",
    "        abs_summ = \" \".join(abs_summ)\n",
    "\n",
    "    print(len(abs_summ.split(\" \")))\n",
    "\n",
    "    # Construct the path correctly\n",
    "    path = os.path.join(output_path, name)\n",
    "    print(f\"Constructed Path: {path}\")  # Debug to check the path\n",
    "\n",
    "    # Normalize the path for consistency\n",
    "    path = os.path.normpath(path)\n",
    "\n",
    "    # Debug: Check if the directory exists\n",
    "    directory = os.path.dirname(path)\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Directory does not exist: {directory}\")\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory created: {directory}\")\n",
    "\n",
    "    # Debug: Check if the full path exists before opening the file\n",
    "    if os.path.exists(path):\n",
    "        print(f\"The file already exists: {path}\")\n",
    "    else:\n",
    "        print(f\"The file does not exist: {path}\")\n",
    "\n",
    "    # Write the file\n",
    "    with open(path, 'w') as file:\n",
    "        file.write(abs_summ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f33b2444-b55b-4734-ba4d-3de11324c3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE scores for 1181:\n",
      "ROUGE-1: Score(precision=0.5337423312883436, recall=0.54375, fmeasure=0.5386996904024768)\n",
      "ROUGE-2: Score(precision=0.19692307692307692, recall=0.2006269592476489, fmeasure=0.19875776397515527)\n",
      "ROUGE-L: Score(precision=0.2361963190184049, recall=0.240625, fmeasure=0.23839009287925697)\n",
      "\n",
      "ROUGE scores for 1195:\n",
      "ROUGE-1: Score(precision=0.4670433145009416, recall=0.4635514018691589, fmeasure=0.4652908067542214)\n",
      "ROUGE-2: Score(precision=0.14150943396226415, recall=0.1404494382022472, fmeasure=0.14097744360902256)\n",
      "ROUGE-L: Score(precision=0.18832391713747645, recall=0.18691588785046728, fmeasure=0.18761726078799248)\n",
      "\n",
      "ROUGE scores for 1329:\n",
      "ROUGE-1: Score(precision=0.4943181818181818, recall=0.5058139534883721, fmeasure=0.5)\n",
      "ROUGE-2: Score(precision=0.21652421652421652, recall=0.22157434402332363, fmeasure=0.21902017291066284)\n",
      "ROUGE-L: Score(precision=0.23295454545454544, recall=0.23837209302325582, fmeasure=0.235632183908046)\n",
      "\n",
      "ROUGE scores for 1378:\n",
      "ROUGE-1: Score(precision=0.3942307692307692, recall=0.4039408866995074, fmeasure=0.3990267639902676)\n",
      "ROUGE-2: Score(precision=0.08695652173913043, recall=0.0891089108910891, fmeasure=0.08801955990220048)\n",
      "ROUGE-L: Score(precision=0.16826923076923078, recall=0.1724137931034483, fmeasure=0.17031630170316303)\n",
      "\n",
      "ROUGE scores for 1406:\n",
      "ROUGE-1: Score(precision=0.46973365617433416, recall=0.470873786407767, fmeasure=0.4703030303030303)\n",
      "ROUGE-2: Score(precision=0.15776699029126215, recall=0.15815085158150852, fmeasure=0.15795868772782504)\n",
      "ROUGE-L: Score(precision=0.21307506053268765, recall=0.21359223300970873, fmeasure=0.21333333333333332)\n",
      "\n",
      "ROUGE scores for 1522:\n",
      "ROUGE-1: Score(precision=0.3874538745387454, recall=0.3860294117647059, fmeasure=0.3867403314917127)\n",
      "ROUGE-2: Score(precision=0.1259259259259259, recall=0.12546125461254612, fmeasure=0.12569316081330867)\n",
      "ROUGE-L: Score(precision=0.1992619926199262, recall=0.19852941176470587, fmeasure=0.19889502762430938)\n",
      "\n",
      "ROUGE scores for 1531:\n",
      "ROUGE-1: Score(precision=0.5631067961165048, recall=0.5675146771037182, fmeasure=0.5653021442495126)\n",
      "ROUGE-2: Score(precision=0.30544747081712065, recall=0.307843137254902, fmeasure=0.306640625)\n",
      "ROUGE-L: Score(precision=0.33980582524271846, recall=0.3424657534246575, fmeasure=0.341130604288499)\n",
      "\n",
      "ROUGE scores for 1697:\n",
      "ROUGE-1: Score(precision=0.6530172413793104, recall=0.6558441558441559, fmeasure=0.6544276457883369)\n",
      "ROUGE-2: Score(precision=0.3076923076923077, recall=0.30902527075812275, fmeasure=0.30835734870317005)\n",
      "ROUGE-L: Score(precision=0.22126436781609196, recall=0.2222222222222222, fmeasure=0.22174226061915048)\n",
      "\n",
      "ROUGE scores for 1762:\n",
      "ROUGE-1: Score(precision=0.5231316725978647, recall=0.5259391771019678, fmeasure=0.5245316681534343)\n",
      "ROUGE-2: Score(precision=0.18181818181818182, recall=0.1827956989247312, fmeasure=0.18230563002680963)\n",
      "ROUGE-L: Score(precision=0.20818505338078291, recall=0.20930232558139536, fmeasure=0.20874219446922393)\n",
      "\n",
      "ROUGE scores for 1778:\n",
      "ROUGE-1: Score(precision=0.6851063829787234, recall=0.6708333333333333, fmeasure=0.6778947368421053)\n",
      "ROUGE-2: Score(precision=0.4200426439232409, recall=0.4112734864300626, fmeasure=0.41561181434599154)\n",
      "ROUGE-L: Score(precision=0.3553191489361702, recall=0.34791666666666665, fmeasure=0.35157894736842105)\n",
      "\n",
      "ROUGE scores for 1789:\n",
      "ROUGE-1: Score(precision=0.5173410404624278, recall=0.521865889212828, fmeasure=0.5195936139332367)\n",
      "ROUGE-2: Score(precision=0.16231884057971013, recall=0.16374269005847952, fmeasure=0.16302765647743814)\n",
      "ROUGE-L: Score(precision=0.18786127167630057, recall=0.18950437317784258, fmeasure=0.18867924528301885)\n",
      "\n",
      "ROUGE scores for 1974:\n",
      "ROUGE-1: Score(precision=0.544954128440367, recall=0.5541044776119403, fmeasure=0.549491211840888)\n",
      "ROUGE-2: Score(precision=0.23529411764705882, recall=0.23925233644859814, fmeasure=0.23725671918443003)\n",
      "ROUGE-L: Score(precision=0.21651376146788992, recall=0.22014925373134328, fmeasure=0.2183163737280296)\n",
      "\n",
      "ROUGE scores for 2035:\n",
      "ROUGE-1: Score(precision=0.5211786372007366, recall=0.5126811594202898, fmeasure=0.5168949771689496)\n",
      "ROUGE-2: Score(precision=0.1992619926199262, recall=0.19600725952813067, fmeasure=0.19762122598353157)\n",
      "ROUGE-L: Score(precision=0.22467771639042358, recall=0.2210144927536232, fmeasure=0.22283105022831048)\n",
      "\n",
      "ROUGE scores for 2052:\n",
      "ROUGE-1: Score(precision=0.5158730158730159, recall=0.5213903743315508, fmeasure=0.5186170212765958)\n",
      "ROUGE-2: Score(precision=0.23178807947019867, recall=0.23427041499330656, fmeasure=0.23302263648468707)\n",
      "ROUGE-L: Score(precision=0.2275132275132275, recall=0.22994652406417113, fmeasure=0.22872340425531917)\n",
      "\n",
      "ROUGE scores for 2065:\n",
      "ROUGE-1: Score(precision=0.551219512195122, recall=0.5530179445350734, fmeasure=0.5521172638436482)\n",
      "ROUGE-2: Score(precision=0.21335504885993486, recall=0.21405228758169934, fmeasure=0.2137030995106036)\n",
      "ROUGE-L: Score(precision=0.22276422764227644, recall=0.2234910277324633, fmeasure=0.22312703583061888)\n",
      "\n",
      "ROUGE scores for 2122:\n",
      "ROUGE-1: Score(precision=0.6872427983539094, recall=0.6867129272680544, fmeasure=0.6869777606376141)\n",
      "ROUGE-2: Score(precision=0.36480576279907384, recall=0.36452442159383036, fmeasure=0.3646650379323647)\n",
      "ROUGE-L: Score(precision=0.2844650205761317, recall=0.28424569519403753, fmeasure=0.28435531559326394)\n",
      "\n",
      "ROUGE scores for 2124:\n",
      "ROUGE-1: Score(precision=0.36904761904761907, recall=0.38271604938271603, fmeasure=0.37575757575757573)\n",
      "ROUGE-2: Score(precision=0.17365269461077845, recall=0.18012422360248448, fmeasure=0.17682926829268292)\n",
      "ROUGE-L: Score(precision=0.22023809523809523, recall=0.22839506172839505, fmeasure=0.22424242424242422)\n",
      "\n",
      "ROUGE scores for 2207:\n",
      "ROUGE-1: Score(precision=0.6480446927374302, recall=0.6382393397524071, fmeasure=0.6431046431046431)\n",
      "ROUGE-2: Score(precision=0.35384615384615387, recall=0.3484848484848485, fmeasure=0.351145038167939)\n",
      "ROUGE-L: Score(precision=0.3226256983240223, recall=0.3177441540577717, fmeasure=0.3201663201663202)\n",
      "\n",
      "ROUGE scores for 2248:\n",
      "ROUGE-1: Score(precision=0.5227272727272727, recall=0.5227272727272727, fmeasure=0.5227272727272727)\n",
      "ROUGE-2: Score(precision=0.14886164623467601, recall=0.14886164623467601, fmeasure=0.14886164623467601)\n",
      "ROUGE-L: Score(precision=0.1888111888111888, recall=0.1888111888111888, fmeasure=0.1888111888111888)\n",
      "\n",
      "ROUGE scores for 2256:\n",
      "ROUGE-1: Score(precision=0.543026706231454, recall=0.5438335809806835, fmeasure=0.5434298440979956)\n",
      "ROUGE-2: Score(precision=0.22585438335809807, recall=0.2261904761904762, fmeasure=0.22602230483271374)\n",
      "ROUGE-L: Score(precision=0.20919881305637983, recall=0.20950965824665677, fmeasure=0.2093541202672606)\n",
      "\n",
      "ROUGE scores for 2304:\n",
      "ROUGE-1: Score(precision=0.6043829296424452, recall=0.6193853427895981, fmeasure=0.6117921774664332)\n",
      "ROUGE-2: Score(precision=0.2909930715935335, recall=0.2982248520710059, fmeasure=0.2945645821157218)\n",
      "ROUGE-L: Score(precision=0.21568627450980393, recall=0.22104018912529552, fmeasure=0.21833041447752483)\n",
      "\n",
      "ROUGE scores for 232:\n",
      "ROUGE-1: Score(precision=0.6586921850079744, recall=0.6600958977091103, fmeasure=0.6593932943054815)\n",
      "ROUGE-2: Score(precision=0.28404255319148936, recall=0.2846481876332623, fmeasure=0.28434504792332266)\n",
      "ROUGE-L: Score(precision=0.2301967038809144, recall=0.23068726691529035, fmeasure=0.23044172432144755)\n",
      "\n",
      "ROUGE scores for 2392:\n",
      "ROUGE-1: Score(precision=0.5173824130879345, recall=0.5315126050420168, fmeasure=0.5243523316062176)\n",
      "ROUGE-2: Score(precision=0.17827868852459017, recall=0.1831578947368421, fmeasure=0.1806853582554517)\n",
      "ROUGE-L: Score(precision=0.20449897750511248, recall=0.21008403361344538, fmeasure=0.20725388601036268)\n",
      "\n",
      "ROUGE scores for 2440:\n",
      "ROUGE-1: Score(precision=0.5531914893617021, recall=0.5632582322357019, fmeasure=0.55817947617003)\n",
      "ROUGE-2: Score(precision=0.19591141396933562, recall=0.199479618386817, fmeasure=0.19767941555651056)\n",
      "ROUGE-L: Score(precision=0.19574468085106383, recall=0.19930675909878684, fmeasure=0.19750966079862603)\n",
      "\n",
      "ROUGE scores for 2593:\n",
      "ROUGE-1: Score(precision=0.580441640378549, recall=0.5869218500797448, fmeasure=0.5836637589214909)\n",
      "ROUGE-2: Score(precision=0.26066350710900477, recall=0.26357827476038337, fmeasure=0.26211278792692616)\n",
      "ROUGE-L: Score(precision=0.2555205047318612, recall=0.2583732057416268, fmeasure=0.25693893735130857)\n",
      "\n",
      "ROUGE scores for 2609:\n",
      "ROUGE-1: Score(precision=0.36901408450704226, recall=0.37971014492753624, fmeasure=0.37428571428571433)\n",
      "ROUGE-2: Score(precision=0.13559322033898305, recall=0.13953488372093023, fmeasure=0.13753581661891118)\n",
      "ROUGE-L: Score(precision=0.16619718309859155, recall=0.17101449275362318, fmeasure=0.16857142857142857)\n",
      "\n",
      "ROUGE scores for 2627:\n",
      "ROUGE-1: Score(precision=0.5046480743691899, recall=0.5087014725568942, fmeasure=0.5066666666666666)\n",
      "ROUGE-2: Score(precision=0.1981382978723404, recall=0.19973190348525469, fmeasure=0.19893190921228304)\n",
      "ROUGE-L: Score(precision=0.18193891102257637, recall=0.18340026773761714, fmeasure=0.18266666666666667)\n",
      "\n",
      "ROUGE scores for 2649:\n",
      "ROUGE-1: Score(precision=0.45585215605749485, recall=0.47639484978540775, fmeasure=0.46589716684155297)\n",
      "ROUGE-2: Score(precision=0.17901234567901234, recall=0.1870967741935484, fmeasure=0.18296529968454256)\n",
      "ROUGE-L: Score(precision=0.19507186858316222, recall=0.20386266094420602, fmeasure=0.19937040923399793)\n",
      "\n",
      "ROUGE scores for 2657:\n",
      "ROUGE-1: Score(precision=0.5950782997762863, recall=0.6059225512528473, fmeasure=0.600451467268623)\n",
      "ROUGE-2: Score(precision=0.37668161434977576, recall=0.3835616438356164, fmeasure=0.38009049773755654)\n",
      "ROUGE-L: Score(precision=0.39373601789709173, recall=0.4009111617312073, fmeasure=0.3972911963882619)\n",
      "\n",
      "ROUGE scores for 266:\n",
      "ROUGE-1: Score(precision=0.40096618357487923, recall=0.40487804878048783, fmeasure=0.4029126213592233)\n",
      "ROUGE-2: Score(precision=0.11864406779661017, recall=0.1198044009779951, fmeasure=0.1192214111922141)\n",
      "ROUGE-L: Score(precision=0.21014492753623187, recall=0.2121951219512195, fmeasure=0.2111650485436893)\n",
      "\n",
      "ROUGE scores for 2727:\n",
      "ROUGE-1: Score(precision=0.384375, recall=0.3867924528301887, fmeasure=0.38557993730407525)\n",
      "ROUGE-2: Score(precision=0.14733542319749215, recall=0.14826498422712933, fmeasure=0.1477987421383648)\n",
      "ROUGE-L: Score(precision=0.190625, recall=0.1918238993710692, fmeasure=0.19122257053291533)\n",
      "\n",
      "ROUGE scores for 2796:\n",
      "ROUGE-1: Score(precision=0.5093945720250522, recall=0.5126050420168067, fmeasure=0.5109947643979058)\n",
      "ROUGE-2: Score(precision=0.17154811715481172, recall=0.1726315789473684, fmeasure=0.1720881427072403)\n",
      "ROUGE-L: Score(precision=0.1837160751565762, recall=0.18487394957983194, fmeasure=0.18429319371727748)\n",
      "\n",
      "ROUGE scores for 2913:\n",
      "ROUGE-1: Score(precision=0.556910569105691, recall=0.5626283367556468, fmeasure=0.5597548518896833)\n",
      "ROUGE-2: Score(precision=0.2708757637474542, recall=0.2736625514403292, fmeasure=0.27226202661207777)\n",
      "ROUGE-L: Score(precision=0.2682926829268293, recall=0.27104722792607805, fmeasure=0.2696629213483146)\n",
      "\n",
      "ROUGE scores for 3019:\n",
      "ROUGE-1: Score(precision=0.3978102189781022, recall=0.4022140221402214, fmeasure=0.4)\n",
      "ROUGE-2: Score(precision=0.1282051282051282, recall=0.12962962962962962, fmeasure=0.12891344383057088)\n",
      "ROUGE-L: Score(precision=0.17153284671532848, recall=0.17343173431734318, fmeasure=0.1724770642201835)\n",
      "\n",
      "ROUGE scores for 314:\n",
      "ROUGE-1: Score(precision=0.30115830115830117, recall=0.2899628252788104, fmeasure=0.2954545454545454)\n",
      "ROUGE-2: Score(precision=0.06201550387596899, recall=0.05970149253731343, fmeasure=0.06083650190114068)\n",
      "ROUGE-L: Score(precision=0.15444015444015444, recall=0.14869888475836432, fmeasure=0.15151515151515152)\n",
      "\n",
      "ROUGE scores for 3168:\n",
      "ROUGE-1: Score(precision=0.6, recall=0.5952063914780293, fmeasure=0.5975935828877006)\n",
      "ROUGE-2: Score(precision=0.27553763440860213, recall=0.2733333333333333, fmeasure=0.27443105756358765)\n",
      "ROUGE-L: Score(precision=0.2912751677852349, recall=0.28894806924101196, fmeasure=0.2901069518716578)\n",
      "\n",
      "ROUGE scores for 3210:\n",
      "ROUGE-1: Score(precision=0.42036124794745483, recall=0.4317032040472175, fmeasure=0.4259567387687188)\n",
      "ROUGE-2: Score(precision=0.09210526315789473, recall=0.0945945945945946, fmeasure=0.09333333333333334)\n",
      "ROUGE-L: Score(precision=0.18555008210180624, recall=0.1905564924114671, fmeasure=0.18801996672212978)\n",
      "\n",
      "ROUGE scores for 3292:\n",
      "ROUGE-1: Score(precision=0.5509499136442142, recall=0.5481099656357389, fmeasure=0.549526270456503)\n",
      "ROUGE-2: Score(precision=0.24048442906574394, recall=0.23924268502581755, fmeasure=0.23986194995685933)\n",
      "ROUGE-L: Score(precision=0.26252158894645944, recall=0.2611683848797251, fmeasure=0.26184323858742464)\n",
      "\n",
      "ROUGE scores for 3356:\n",
      "ROUGE-1: Score(precision=0.42777777777777776, recall=0.42424242424242425, fmeasure=0.4260027662517289)\n",
      "ROUGE-2: Score(precision=0.12534818941504178, recall=0.12430939226519337, fmeasure=0.1248266296809986)\n",
      "ROUGE-L: Score(precision=0.18333333333333332, recall=0.18181818181818182, fmeasure=0.18257261410788383)\n",
      "\n",
      "ROUGE scores for 3436:\n",
      "ROUGE-1: Score(precision=0.5077881619937694, recall=0.5207667731629393, fmeasure=0.5141955835962144)\n",
      "ROUGE-2: Score(precision=0.171875, recall=0.1762820512820513, fmeasure=0.17405063291139242)\n",
      "ROUGE-L: Score(precision=0.22741433021806853, recall=0.23322683706070288, fmeasure=0.23028391167192427)\n",
      "\n",
      "ROUGE scores for 3442:\n",
      "ROUGE-1: Score(precision=0.43134328358208956, recall=0.4345864661654135, fmeasure=0.4329588014981273)\n",
      "ROUGE-2: Score(precision=0.11659192825112108, recall=0.11746987951807229, fmeasure=0.11702925731432857)\n",
      "ROUGE-L: Score(precision=0.2, recall=0.20150375939849624, fmeasure=0.200749063670412)\n",
      "\n",
      "ROUGE scores for 3531:\n",
      "ROUGE-1: Score(precision=0.49922239502332816, recall=0.5169082125603864, fmeasure=0.5079113924050632)\n",
      "ROUGE-2: Score(precision=0.1853582554517134, recall=0.19193548387096773, fmeasure=0.18858954041204437)\n",
      "ROUGE-L: Score(precision=0.18973561430793157, recall=0.1964573268921095, fmeasure=0.1930379746835443)\n",
      "\n",
      "ROUGE scores for 3542:\n",
      "ROUGE-1: Score(precision=0.4280442804428044, recall=0.44106463878326996, fmeasure=0.4344569288389513)\n",
      "ROUGE-2: Score(precision=0.14814814814814814, recall=0.15267175572519084, fmeasure=0.15037593984962405)\n",
      "ROUGE-L: Score(precision=0.2066420664206642, recall=0.21292775665399238, fmeasure=0.2097378277153558)\n",
      "\n",
      "ROUGE scores for 3602:\n",
      "ROUGE-1: Score(precision=0.4326241134751773, recall=0.43990384615384615, fmeasure=0.43623361144219314)\n",
      "ROUGE-2: Score(precision=0.11611374407582939, recall=0.1180722891566265, fmeasure=0.11708482676224612)\n",
      "ROUGE-L: Score(precision=0.16784869976359337, recall=0.17067307692307693, fmeasure=0.16924910607866508)\n",
      "\n",
      "ROUGE scores for 362:\n",
      "ROUGE-1: Score(precision=0.5876685934489403, recall=0.5776515151515151, fmeasure=0.5826170009551098)\n",
      "ROUGE-2: Score(precision=0.29026036644165865, recall=0.2853080568720379, fmeasure=0.28776290630975143)\n",
      "ROUGE-L: Score(precision=0.302504816955684, recall=0.29734848484848486, fmeasure=0.2999044890162369)\n",
      "\n",
      "ROUGE scores for 380:\n",
      "ROUGE-1: Score(precision=0.4276315789473684, recall=0.4234527687296417, fmeasure=0.425531914893617)\n",
      "ROUGE-2: Score(precision=0.14521452145214522, recall=0.1437908496732026, fmeasure=0.1444991789819376)\n",
      "ROUGE-L: Score(precision=0.19407894736842105, recall=0.19218241042345277, fmeasure=0.19312602291325695)\n",
      "\n",
      "ROUGE scores for 3844:\n",
      "ROUGE-1: Score(precision=0.6986394557823129, recall=0.702943189596167, fmeasure=0.7007847151142954)\n",
      "ROUGE-2: Score(precision=0.45132743362831856, recall=0.4541095890410959, fmeasure=0.45271423694093543)\n",
      "ROUGE-L: Score(precision=0.35306122448979593, recall=0.35523613963039014, fmeasure=0.3541453428863869)\n",
      "\n",
      "ROUGE scores for 3893:\n",
      "ROUGE-1: Score(precision=0.6012526096033403, recall=0.6012526096033403, fmeasure=0.6012526096033403)\n",
      "ROUGE-2: Score(precision=0.2727272727272727, recall=0.2727272727272727, fmeasure=0.2727272727272727)\n",
      "ROUGE-L: Score(precision=0.22129436325678498, recall=0.22129436325678498, fmeasure=0.22129436325678498)\n",
      "\n",
      "ROUGE scores for 3924:\n",
      "ROUGE-1: Score(precision=0.366412213740458, recall=0.3764705882352941, fmeasure=0.3713733075435203)\n",
      "ROUGE-2: Score(precision=0.0840764331210191, recall=0.08638743455497382, fmeasure=0.08521626856036152)\n",
      "ROUGE-L: Score(precision=0.1743002544529262, recall=0.17908496732026144, fmeasure=0.1766602192134107)\n",
      "\n",
      "ROUGE scores for 4071:\n",
      "ROUGE-1: Score(precision=0.5847076461769115, recall=0.5891238670694864, fmeasure=0.5869074492099322)\n",
      "ROUGE-2: Score(precision=0.2702702702702703, recall=0.2723146747352496, fmeasure=0.2712886209495102)\n",
      "ROUGE-L: Score(precision=0.24287856071964017, recall=0.24471299093655588, fmeasure=0.2437923250564334)\n",
      "\n",
      "ROUGE scores for 415:\n",
      "ROUGE-1: Score(precision=0.37254901960784315, recall=0.3713355048859935, fmeasure=0.3719412724306689)\n",
      "ROUGE-2: Score(precision=0.09836065573770492, recall=0.09803921568627451, fmeasure=0.09819967266775778)\n",
      "ROUGE-L: Score(precision=0.17973856209150327, recall=0.1791530944625407, fmeasure=0.17944535073409462)\n",
      "\n",
      "ROUGE scores for 4316:\n",
      "ROUGE-1: Score(precision=0.6046109510086455, recall=0.6134502923976608, fmeasure=0.6089985486211902)\n",
      "ROUGE-2: Score(precision=0.25893886966551327, recall=0.26272674078408426, fmeasure=0.2608190531513215)\n",
      "ROUGE-L: Score(precision=0.22074927953890489, recall=0.2239766081871345, fmeasure=0.22235123367198836)\n",
      "\n",
      "ROUGE scores for 4451:\n",
      "ROUGE-1: Score(precision=0.5593803786574871, recall=0.5652173913043478, fmeasure=0.5622837370242215)\n",
      "ROUGE-2: Score(precision=0.21724137931034482, recall=0.21951219512195122, fmeasure=0.21837088388214906)\n",
      "ROUGE-L: Score(precision=0.24440619621342513, recall=0.24695652173913044, fmeasure=0.24567474048442905)\n",
      "\n",
      "ROUGE scores for 4480:\n",
      "ROUGE-1: Score(precision=0.7266031195840554, recall=0.7335958005249343, fmeasure=0.7300827165868523)\n",
      "ROUGE-2: Score(precision=0.4646727351538795, recall=0.46914660831509847, fmeasure=0.46689895470383275)\n",
      "ROUGE-L: Score(precision=0.32365684575389947, recall=0.32677165354330706, fmeasure=0.32520679146713105)\n",
      "\n",
      "ROUGE scores for 4568:\n",
      "ROUGE-1: Score(precision=0.5126903553299492, recall=0.5055055055055055, fmeasure=0.5090725806451613)\n",
      "ROUGE-2: Score(precision=0.18292682926829268, recall=0.18036072144288579, fmeasure=0.18163471241170534)\n",
      "ROUGE-L: Score(precision=0.19898477157360406, recall=0.1961961961961962, fmeasure=0.19758064516129029)\n",
      "\n",
      "ROUGE scores for 4641:\n",
      "ROUGE-1: Score(precision=0.5495251017639078, recall=0.5567010309278351, fmeasure=0.5530897917377946)\n",
      "ROUGE-2: Score(precision=0.2111337406653089, recall=0.21389270976616231, fmeasure=0.2125042705842159)\n",
      "ROUGE-L: Score(precision=0.19877883310719133, recall=0.2013745704467354, fmeasure=0.20006828269033802)\n",
      "\n",
      "ROUGE scores for 4782:\n",
      "ROUGE-1: Score(precision=0.5745554035567716, recall=0.5785123966942148, fmeasure=0.5765271105010296)\n",
      "ROUGE-2: Score(precision=0.3082191780821918, recall=0.3103448275862069, fmeasure=0.30927835051546393)\n",
      "ROUGE-L: Score(precision=0.32558139534883723, recall=0.3278236914600551, fmeasure=0.32669869595058343)\n",
      "\n",
      "ROUGE scores for 4807:\n",
      "ROUGE-1: Score(precision=0.8028933092224232, recall=0.8072727272727273, fmeasure=0.8050770625566637)\n",
      "ROUGE-2: Score(precision=0.6340579710144928, recall=0.6375227686703097, fmeasure=0.6357856494096277)\n",
      "ROUGE-L: Score(precision=0.43399638336347196, recall=0.43636363636363634, fmeasure=0.43517679057116954)\n",
      "\n",
      "ROUGE scores for 4860:\n",
      "ROUGE-1: Score(precision=0.690781796966161, recall=0.7022538552787663, fmeasure=0.6964705882352942)\n",
      "ROUGE-2: Score(precision=0.41939252336448596, recall=0.42636579572446553, fmeasure=0.42285041224970554)\n",
      "ROUGE-L: Score(precision=0.2928821470245041, recall=0.2977461447212337, fmeasure=0.2952941176470588)\n",
      "\n",
      "ROUGE scores for 4917:\n",
      "ROUGE-1: Score(precision=0.7111643220592637, recall=0.7184759600846689, fmeasure=0.7148014440433212)\n",
      "ROUGE-2: Score(precision=0.4221556886227545, recall=0.426497277676951, fmeasure=0.4243153776707794)\n",
      "ROUGE-L: Score(precision=0.32684824902723736, recall=0.33020864832174174, fmeasure=0.3285198555956678)\n",
      "\n",
      "ROUGE scores for 4938:\n",
      "ROUGE-1: Score(precision=0.7116228070175439, recall=0.7235228539576366, fmeasure=0.7175234936428967)\n",
      "ROUGE-2: Score(precision=0.4588364434687157, recall=0.46651785714285715, fmeasure=0.46264526840066406)\n",
      "ROUGE-L: Score(precision=0.38048245614035087, recall=0.38684503901895206, fmeasure=0.38363736871199555)\n",
      "\n",
      "ROUGE scores for 496:\n",
      "ROUGE-1: Score(precision=0.3563218390804598, recall=0.36046511627906974, fmeasure=0.35838150289017345)\n",
      "ROUGE-2: Score(precision=0.0576036866359447, recall=0.05827505827505827, fmeasure=0.05793742757821553)\n",
      "ROUGE-L: Score(precision=0.16091954022988506, recall=0.16279069767441862, fmeasure=0.161849710982659)\n",
      "\n",
      "ROUGE scores for 4963:\n",
      "ROUGE-1: Score(precision=0.7123966942148761, recall=0.7195325542570952, fmeasure=0.7159468438538206)\n",
      "ROUGE-2: Score(precision=0.4817880794701987, recall=0.4866220735785953, fmeasure=0.48419301164725453)\n",
      "ROUGE-L: Score(precision=0.43636363636363634, recall=0.44073455759599334, fmeasure=0.4385382059800665)\n",
      "\n",
      "ROUGE scores for 5141:\n",
      "ROUGE-1: Score(precision=0.6503719447396387, recall=0.6623376623376623, fmeasure=0.6563002680965146)\n",
      "ROUGE-2: Score(precision=0.39361702127659576, recall=0.4008667388949079, fmeasure=0.39720880300590444)\n",
      "ROUGE-L: Score(precision=0.3538788522848034, recall=0.36038961038961037, fmeasure=0.35710455764075066)\n",
      "\n",
      "ROUGE scores for 5142:\n",
      "ROUGE-1: Score(precision=0.35575485799701045, recall=0.39932885906040266, fmeasure=0.3762845849802371)\n",
      "ROUGE-2: Score(precision=0.1062874251497006, recall=0.11932773109243698, fmeasure=0.11243072050673002)\n",
      "ROUGE-L: Score(precision=0.16442451420029897, recall=0.18456375838926176, fmeasure=0.1739130434782609)\n",
      "\n",
      "ROUGE scores for 5248:\n",
      "ROUGE-1: Score(precision=0.6259946949602122, recall=0.6471663619744058, fmeasure=0.6364044943820225)\n",
      "ROUGE-2: Score(precision=0.3973451327433628, recall=0.41079597438243365, fmeasure=0.40395861448493026)\n",
      "ROUGE-L: Score(precision=0.33510167992926615, recall=0.34643510054844606, fmeasure=0.3406741573033708)\n",
      "\n",
      "ROUGE scores for 5266:\n",
      "ROUGE-1: Score(precision=0.7252459016393442, recall=0.7224036577400392, fmeasure=0.7238219895287957)\n",
      "ROUGE-2: Score(precision=0.4382685686178062, recall=0.43655071043606075, fmeasure=0.4374079528718704)\n",
      "ROUGE-L: Score(precision=0.2949180327868852, recall=0.2937622468974527, fmeasure=0.2943390052356021)\n",
      "\n",
      "ROUGE scores for 5364:\n",
      "ROUGE-1: Score(precision=0.6564009661835749, recall=0.6587878787878788, fmeasure=0.6575922565033273)\n",
      "ROUGE-2: Score(precision=0.3198429477499245, recall=0.3210063655653228, fmeasure=0.3204236006051437)\n",
      "ROUGE-L: Score(precision=0.21316425120772947, recall=0.21393939393939393, fmeasure=0.2135511191772535)\n",
      "\n",
      "ROUGE scores for 5397:\n",
      "ROUGE-1: Score(precision=0.5051679586563308, recall=0.5185676392572944, fmeasure=0.5117801047120419)\n",
      "ROUGE-2: Score(precision=0.2095730918499353, recall=0.2151394422310757, fmeasure=0.21231979030144169)\n",
      "ROUGE-L: Score(precision=0.20284237726098192, recall=0.20822281167108753, fmeasure=0.2054973821989529)\n",
      "\n",
      "ROUGE scores for 5471:\n",
      "ROUGE-1: Score(precision=0.634011090573013, recall=0.6447368421052632, fmeasure=0.6393289841565704)\n",
      "ROUGE-2: Score(precision=0.3330249768732655, recall=0.33866415804327377, fmeasure=0.3358208955223881)\n",
      "ROUGE-L: Score(precision=0.2643253234750462, recall=0.26879699248120303, fmeasure=0.26654240447343897)\n",
      "\n",
      "ROUGE scores for 5538:\n",
      "ROUGE-1: Score(precision=0.5612244897959183, recall=0.5662805662805663, fmeasure=0.5637411915438821)\n",
      "ROUGE-2: Score(precision=0.2260536398467433, recall=0.22809278350515463, fmeasure=0.22706863373957667)\n",
      "ROUGE-L: Score(precision=0.20790816326530612, recall=0.2097812097812098, fmeasure=0.2088404868673927)\n",
      "\n",
      "ROUGE scores for 5597:\n",
      "ROUGE-1: Score(precision=0.549079754601227, recall=0.5457317073170732, fmeasure=0.5474006116207951)\n",
      "ROUGE-2: Score(precision=0.24923076923076923, recall=0.24770642201834864, fmeasure=0.24846625766871167)\n",
      "ROUGE-L: Score(precision=0.25766871165644173, recall=0.25609756097560976, fmeasure=0.25688073394495414)\n",
      "\n",
      "ROUGE scores for 5707:\n",
      "ROUGE-1: Score(precision=0.5178571428571429, recall=0.5254529767040552, fmeasure=0.521627408993576)\n",
      "ROUGE-2: Score(precision=0.2025531914893617, recall=0.20552677029360966, fmeasure=0.20402914702100303)\n",
      "ROUGE-L: Score(precision=0.2261904761904762, recall=0.22950819672131148, fmeasure=0.2278372591006424)\n",
      "\n",
      "ROUGE scores for 5861:\n",
      "ROUGE-1: Score(precision=0.5548387096774193, recall=0.5689981096408318, fmeasure=0.5618292113859076)\n",
      "ROUGE-2: Score(precision=0.20571955719557194, recall=0.2109744560075686, fmeasure=0.20831387202241944)\n",
      "ROUGE-L: Score(precision=0.21751152073732719, recall=0.22306238185255198, fmeasure=0.2202519832011199)\n",
      "\n",
      "ROUGE scores for 5888:\n",
      "ROUGE-1: Score(precision=0.3967611336032389, recall=0.43555555555555553, fmeasure=0.4152542372881356)\n",
      "ROUGE-2: Score(precision=0.15447154471544716, recall=0.16964285714285715, fmeasure=0.16170212765957448)\n",
      "ROUGE-L: Score(precision=0.19433198380566802, recall=0.21333333333333335, fmeasure=0.20338983050847462)\n",
      "\n",
      "ROUGE scores for 5937:\n",
      "ROUGE-1: Score(precision=0.5789473684210527, recall=0.5983263598326359, fmeasure=0.5884773662551441)\n",
      "ROUGE-2: Score(precision=0.43089430894308944, recall=0.44537815126050423, fmeasure=0.4380165289256199)\n",
      "ROUGE-L: Score(precision=0.4898785425101215, recall=0.5062761506276151, fmeasure=0.4979423868312758)\n",
      "\n",
      "ROUGE scores for 5994:\n",
      "ROUGE-1: Score(precision=0.5444234404536862, recall=0.5454545454545454, fmeasure=0.5449385052034058)\n",
      "ROUGE-2: Score(precision=0.1892147587511826, recall=0.1895734597156398, fmeasure=0.1893939393939394)\n",
      "ROUGE-L: Score(precision=0.19187145557655955, recall=0.19223484848484848, fmeasure=0.19205298013245034)\n",
      "\n",
      "ROUGE scores for 6003:\n",
      "ROUGE-1: Score(precision=0.6144578313253012, recall=0.6271844660194175, fmeasure=0.6207559256886611)\n",
      "ROUGE-2: Score(precision=0.2703045685279188, recall=0.2759067357512953, fmeasure=0.2730769230769231)\n",
      "ROUGE-L: Score(precision=0.22130627774254916, recall=0.22588996763754046, fmeasure=0.22357463164638056)\n",
      "\n",
      "ROUGE scores for 6118:\n",
      "ROUGE-1: Score(precision=0.5255731922398589, recall=0.5379061371841155, fmeasure=0.5316681534344335)\n",
      "ROUGE-2: Score(precision=0.2773851590106007, recall=0.28390596745027125, fmeasure=0.2806076854334227)\n",
      "ROUGE-L: Score(precision=0.3386243386243386, recall=0.34657039711191334, fmeasure=0.34255129348795715)\n",
      "\n",
      "ROUGE scores for 6157:\n",
      "ROUGE-1: Score(precision=0.6813700051894136, recall=0.6838541666666667, fmeasure=0.6826098258383156)\n",
      "ROUGE-2: Score(precision=0.3707165109034268, recall=0.37206878582595104, fmeasure=0.37139141742522763)\n",
      "ROUGE-L: Score(precision=0.2776336274001038, recall=0.2786458333333333, fmeasure=0.2781388094619183)\n",
      "\n",
      "ROUGE scores for 6245:\n",
      "ROUGE-1: Score(precision=0.4823008849557522, recall=0.5190476190476191, fmeasure=0.5000000000000001)\n",
      "ROUGE-2: Score(precision=0.2088888888888889, recall=0.22488038277511962, fmeasure=0.21658986175115208)\n",
      "ROUGE-L: Score(precision=0.1902654867256637, recall=0.20476190476190476, fmeasure=0.19724770642201833)\n",
      "\n",
      "ROUGE scores for 6270:\n",
      "ROUGE-1: Score(precision=0.4976958525345622, recall=0.4864864864864865, fmeasure=0.4920273348519363)\n",
      "ROUGE-2: Score(precision=0.16166281755196305, recall=0.1580135440180587, fmeasure=0.1598173515981735)\n",
      "ROUGE-L: Score(precision=0.1935483870967742, recall=0.1891891891891892, fmeasure=0.19134396355353078)\n",
      "\n",
      "ROUGE scores for 6276:\n",
      "ROUGE-1: Score(precision=0.5403624382207578, recall=0.5494137353433836, fmeasure=0.5448504983388703)\n",
      "ROUGE-2: Score(precision=0.20462046204620463, recall=0.2080536912751678, fmeasure=0.20632279534109818)\n",
      "ROUGE-L: Score(precision=0.2602965403624382, recall=0.2646566164154104, fmeasure=0.26245847176079734)\n",
      "\n",
      "ROUGE scores for 6413:\n",
      "ROUGE-1: Score(precision=0.6413223140495867, recall=0.6576271186440678, fmeasure=0.6493723849372384)\n",
      "ROUGE-2: Score(precision=0.41721854304635764, recall=0.42784380305602715, fmeasure=0.4224643755238894)\n",
      "ROUGE-L: Score(precision=0.3305785123966942, recall=0.3389830508474576, fmeasure=0.33472803347280333)\n",
      "\n",
      "ROUGE scores for 652:\n",
      "ROUGE-1: Score(precision=0.37398373983739835, recall=0.37551020408163266, fmeasure=0.3747454175152749)\n",
      "ROUGE-2: Score(precision=0.12244897959183673, recall=0.12295081967213115, fmeasure=0.12269938650306748)\n",
      "ROUGE-L: Score(precision=0.17479674796747968, recall=0.17551020408163265, fmeasure=0.17515274949083504)\n",
      "\n",
      "ROUGE scores for 6521:\n",
      "ROUGE-1: Score(precision=0.6786344908769865, recall=0.6996359223300971, fmeasure=0.6889752016731401)\n",
      "ROUGE-2: Score(precision=0.4075382803297998, recall=0.4201578627808136, fmeasure=0.41375186846038864)\n",
      "ROUGE-L: Score(precision=0.3961153619776339, recall=0.408373786407767, fmeasure=0.40215118016133855)\n",
      "\n",
      "ROUGE scores for 660:\n",
      "ROUGE-1: Score(precision=0.4296875, recall=0.43478260869565216, fmeasure=0.43222003929273084)\n",
      "ROUGE-2: Score(precision=0.13111545988258316, recall=0.13267326732673268, fmeasure=0.13188976377952757)\n",
      "ROUGE-L: Score(precision=0.208984375, recall=0.21146245059288538, fmeasure=0.21021611001964635)\n",
      "\n",
      "ROUGE scores for 6622:\n",
      "ROUGE-1: Score(precision=0.5882845188284519, recall=0.585345545378851, fmeasure=0.5868113522537564)\n",
      "ROUGE-2: Score(precision=0.24371859296482412, recall=0.2425, fmeasure=0.24310776942355888)\n",
      "ROUGE-L: Score(precision=0.2694560669456067, recall=0.2681099084096586, fmeasure=0.2687813021702838)\n",
      "\n",
      "ROUGE scores for 6647:\n",
      "ROUGE-1: Score(precision=0.6471506635441062, recall=0.6421378776142526, fmeasure=0.6446345256609644)\n",
      "ROUGE-2: Score(precision=0.35078125, recall=0.34806201550387594, fmeasure=0.34941634241245134)\n",
      "ROUGE-L: Score(precision=0.26697892271662765, recall=0.26491092176607284, fmeasure=0.26594090202177295)\n",
      "\n",
      "ROUGE scores for 6668:\n",
      "ROUGE-1: Score(precision=0.6384297520661157, recall=0.6560509554140127, fmeasure=0.6471204188481676)\n",
      "ROUGE-2: Score(precision=0.3747412008281574, recall=0.3851063829787234, fmeasure=0.37985309548793283)\n",
      "ROUGE-L: Score(precision=0.3987603305785124, recall=0.40976645435244163, fmeasure=0.4041884816753927)\n",
      "\n",
      "ROUGE scores for 6728:\n",
      "ROUGE-1: Score(precision=0.6402714932126696, recall=0.6345291479820628, fmeasure=0.6373873873873874)\n",
      "ROUGE-2: Score(precision=0.36054421768707484, recall=0.35730337078651686, fmeasure=0.35891647855530473)\n",
      "ROUGE-L: Score(precision=0.3054298642533937, recall=0.30269058295964124, fmeasure=0.30405405405405406)\n",
      "\n",
      "ROUGE scores for 6778:\n",
      "ROUGE-1: Score(precision=0.7473935061066428, recall=0.7423076923076923, fmeasure=0.7448419177675523)\n",
      "ROUGE-2: Score(precision=0.4207547169811321, recall=0.41789131078015584, fmeasure=0.4193181255876095)\n",
      "ROUGE-L: Score(precision=0.22539966239698142, recall=0.22386587771203156, fmeasure=0.2246301518974816)\n",
      "\n",
      "ROUGE scores for 6852:\n",
      "ROUGE-1: Score(precision=0.6238938053097345, recall=0.6304023845007451, fmeasure=0.6271312083024463)\n",
      "ROUGE-2: Score(precision=0.3722304283604136, recall=0.3761194029850746, fmeasure=0.37416481069042323)\n",
      "ROUGE-L: Score(precision=0.3584070796460177, recall=0.3621460506706408, fmeasure=0.3602668643439585)\n",
      "\n",
      "ROUGE scores for 6881:\n",
      "ROUGE-1: Score(precision=0.5549132947976878, recall=0.5647058823529412, fmeasure=0.5597667638483964)\n",
      "ROUGE-2: Score(precision=0.27314814814814814, recall=0.2779740871613663, fmeasure=0.2755399883245767)\n",
      "ROUGE-L: Score(precision=0.2901734104046243, recall=0.2952941176470588, fmeasure=0.2927113702623907)\n",
      "\n",
      "ROUGE scores for 690:\n",
      "ROUGE-1: Score(precision=0.6545961002785515, recall=0.6682464454976303, fmeasure=0.6613508442776735)\n",
      "ROUGE-2: Score(precision=0.3680297397769517, recall=0.3757115749525617, fmeasure=0.371830985915493)\n",
      "ROUGE-L: Score(precision=0.255338904363974, recall=0.26066350710900477, fmeasure=0.2579737335834897)\n",
      "\n",
      "ROUGE scores for 7109:\n",
      "ROUGE-1: Score(precision=0.584518167456556, recall=0.5882352941176471, fmeasure=0.5863708399366087)\n",
      "ROUGE-2: Score(precision=0.33069620253164556, recall=0.3328025477707006, fmeasure=0.33174603174603173)\n",
      "ROUGE-L: Score(precision=0.24960505529225907, recall=0.25119236883942764, fmeasure=0.25039619651347067)\n",
      "\n",
      "ROUGE scores for 7130:\n",
      "ROUGE-1: Score(precision=0.6649819494584838, recall=0.6645021645021645, fmeasure=0.6647419704077949)\n",
      "ROUGE-2: Score(precision=0.3388728323699422, recall=0.3386281588447653, fmeasure=0.3387504514265078)\n",
      "ROUGE-L: Score(precision=0.28592057761732853, recall=0.2857142857142857, fmeasure=0.28581739444243953)\n",
      "\n",
      "ROUGE scores for 715:\n",
      "ROUGE-1: Score(precision=0.4342629482071713, recall=0.436, fmeasure=0.4351297405189621)\n",
      "ROUGE-2: Score(precision=0.128, recall=0.1285140562248996, fmeasure=0.1282565130260521)\n",
      "ROUGE-L: Score(precision=0.17928286852589642, recall=0.18, fmeasure=0.17964071856287428)\n",
      "\n",
      "ROUGE scores for 78:\n",
      "ROUGE-1: Score(precision=0.42401960784313725, recall=0.43686868686868685, fmeasure=0.43034825870646765)\n",
      "ROUGE-2: Score(precision=0.085995085995086, recall=0.08860759493670886, fmeasure=0.08728179551122194)\n",
      "ROUGE-L: Score(precision=0.18137254901960784, recall=0.18686868686868688, fmeasure=0.18407960199004975)\n",
      "\n",
      "ROUGE scores for 784:\n",
      "ROUGE-1: Score(precision=0.47288503253796094, recall=0.4698275862068966, fmeasure=0.4713513513513513)\n",
      "ROUGE-2: Score(precision=0.15217391304347827, recall=0.1511879049676026, fmeasure=0.15167930660888407)\n",
      "ROUGE-L: Score(precision=0.19088937093275488, recall=0.1896551724137931, fmeasure=0.19027027027027027)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Define paths\n",
    "original_summaries_dir = './summary'   \n",
    "generated_summaries_dir = './output_gpt2/judgement'\n",
    "\n",
    "def read_summary(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read().strip()\n",
    "\n",
    "original_summaries = {}\n",
    "generated_summaries = {}\n",
    "\n",
    "# Process original summaries\n",
    "for filename in os.listdir(original_summaries_dir):\n",
    "    # Normalize paths\n",
    "    original_file_path = os.path.normpath(os.path.join(original_summaries_dir, filename))\n",
    "    generated_file_path = os.path.normpath(os.path.join(generated_summaries_dir, filename))\n",
    "    \n",
    "    # Extract base name without extension\n",
    "    name = os.path.splitext(filename)[0]\n",
    "\n",
    "    # Check if the corresponding file exists in generated summaries\n",
    "    if not os.path.exists(generated_file_path):\n",
    "        print(f\"File not found in generated summaries: {generated_file_path}\")\n",
    "        continue\n",
    "\n",
    "    # Read files\n",
    "    original_summaries[name] = read_summary(original_file_path)\n",
    "    generated_summaries[name] = read_summary(generated_file_path)\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# Function to compute ROUGE scores\n",
    "def compute_rouge(original, generated):\n",
    "    scores = scorer.score(original, generated)\n",
    "    return scores\n",
    "\n",
    "# Compute and display ROUGE scores\n",
    "for name in original_summaries:\n",
    "    if name not in generated_summaries:\n",
    "        print(f\"Generated summary missing for: {name}\")\n",
    "        continue\n",
    "\n",
    "    original = original_summaries[name]\n",
    "    generated = generated_summaries[name]\n",
    "\n",
    "    rouge_scores = compute_rouge(original, generated)\n",
    "    print(f\"ROUGE scores for {name}:\")\n",
    "    print(f\"ROUGE-1: {rouge_scores['rouge1']}\")\n",
    "    print(f\"ROUGE-2: {rouge_scores['rouge2']}\")\n",
    "    print(f\"ROUGE-L: {rouge_scores['rougeL']}\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1f28227-9d96-4b11-92be-6fd044d0ded7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1 F1 score: 0.5472\n",
      "Average ROUGE-2 F1 score: 0.2501\n",
      "Average ROUGE-L F1 score: 0.2481\n"
     ]
    }
   ],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "def compute_rouge(original, generated):\n",
    "    scores = scorer.score(original, generated)\n",
    "    return scores\n",
    "\n",
    "rouge1_f1_total = 0\n",
    "rouge2_f1_total = 0\n",
    "rougeL_f1_total = 0\n",
    "num_summaries = len(original_summaries)\n",
    "\n",
    "for name in original_summaries:\n",
    "    original = original_summaries[name]\n",
    "    generated = generated_summaries[name]\n",
    "\n",
    "    rouge_scores = compute_rouge(original, generated)\n",
    "\n",
    "    rouge1_f1_total += rouge_scores['rouge1'].fmeasure\n",
    "    rouge2_f1_total += rouge_scores['rouge2'].fmeasure\n",
    "    rougeL_f1_total += rouge_scores['rougeL'].fmeasure\n",
    "\n",
    "avg_rouge1_f1 = rouge1_f1_total / num_summaries\n",
    "avg_rouge2_f1 = rouge2_f1_total / num_summaries\n",
    "avg_rougeL_f1 = rougeL_f1_total / num_summaries\n",
    "\n",
    "print(f\"Average ROUGE-1 F1 score: {avg_rouge1_f1:.4f}\")\n",
    "print(f\"Average ROUGE-2 F1 score: {avg_rouge2_f1:.4f}\")\n",
    "print(f\"Average ROUGE-L F1 score: {avg_rougeL_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159f14d9-ca87-4319-8bac-8fa7c9dbc607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
